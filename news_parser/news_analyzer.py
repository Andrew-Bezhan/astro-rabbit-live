"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
"""

import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import schedule
import threading
import time

from .newsdata_client import NewsDataClient
from embedding.embedding_manager import EmbeddingManager
from utils.logger import setup_logger

logger = setup_logger()


class NewsAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
        self.news_client = NewsDataClient()
        self.embedding_manager = EmbeddingManager()
        self.is_running = False
        self.scheduler_thread = None
        
        logger.info("üìä NewsAnalyzer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    async def analyze_news_for_company(self, company_sphere: str, 
                                     days_back: int = 7) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–æ–º–ø–∞–Ω–∏–∏
        
        Args:
            company_sphere (str): –°—Ñ–µ—Ä–∞ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–∏
            days_back (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            Dict[str, Any]: –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Å—Ñ–µ—Ä–µ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            sphere_news = await self.news_client.get_news_by_sphere(
                company_sphere, limit=15
            )
            
            # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–∏–µ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏
            all_news = await self.news_client.get_all_business_news(
                limit_per_category=5
            )
            
            # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
            sphere_news = sphere_news or []
            all_news = all_news or {}
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
            all_news_list = sum(all_news.values(), []) if all_news else []
            combined_news = sphere_news + all_news_list
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –∫–æ–º–ø–∞–Ω–∏—é
            analysis = {
                'sphere_specific': self._analyze_sphere_impact(sphere_news, company_sphere),
                'general_economic': self._analyze_general_impact(all_news),
                'market_sentiment': self._calculate_market_sentiment(combined_news),
                'key_trends': self._extract_key_trends(sphere_news),
                'risks_and_opportunities': self._identify_risks_opportunities(
                    sphere_news, company_sphere
                ),
                'summary': self._create_news_summary(sphere_news, all_news)
            }
            
            logger.info(f"üìà –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è —Å—Ñ–µ—Ä—ã '{company_sphere}' –∑–∞–≤–µ—Ä—à–µ–Ω")
            return analysis
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–∏: {e}")
            return self._get_empty_analysis()
    
    async def get_daily_news_digest(self) -> str:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —Å–≤–æ–¥–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π
        
        Returns:
            str: –¢–µ–∫—Å—Ç–æ–≤–∞—è —Å–≤–æ–¥–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏
            summary = await self.news_client.get_fresh_news_summary(hours_back=24)
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            all_news = await self.news_client.get_all_business_news(
                limit_per_category=3
            )
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Å–≤–æ–¥–∫—É
            digest_parts = [
                "üåÖ **–ï–ñ–ï–î–ù–ï–í–ù–ê–Ø –°–í–û–î–ö–ê –ù–û–í–û–°–¢–ï–ô**",
                f"üìÖ {datetime.now().strftime('%d.%m.%Y')}",
                "",
                summary
            ]
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã
            trends = self._extract_daily_trends(all_news)
            if trends:
                digest_parts.extend(["", "üìä **–ö–õ–Æ–ß–ï–í–´–ï –¢–†–ï–ù–î–´:**"] + trends)
            
            digest = '\n'.join(digest_parts)
            logger.info("üì∞ –ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è —Å–≤–æ–¥–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∞")
            
            return digest
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —Å–≤–æ–¥–∫–∏: {e}")
            return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —Å–≤–æ–¥–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π."
    
    async def start_daily_parsing(self):
        """–ó–∞–ø—É—Å–∫ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        try:
            if self.is_running:
                logger.warning("‚ö†Ô∏è –ü–∞—Ä—Å–µ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —É–∂–µ –∑–∞–ø—É—â–µ–Ω")
                return
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ
            schedule.clear()  # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –∑–∞–¥–∞—á–∏
            
            # –ü–∞—Ä—Å–∏–Ω–≥ –≤ 07:00 —É—Ç—Ä–∞
            schedule.every().day.at("07:00").do(self._scheduled_news_parsing)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            self.is_running = True
            self.scheduler_thread = threading.Thread(target=self._run_scheduler, daemon=True)
            self.scheduler_thread.start()
            
            logger.info("‚è∞ –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞–ø—É—â–µ–Ω (07:00)")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞: {e}")
    
    def stop_daily_parsing(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        try:
            self.is_running = False
            schedule.clear()
            
            if self.scheduler_thread and self.scheduler_thread.is_alive():
                self.scheduler_thread.join(timeout=5)
            
            logger.info("‚èπÔ∏è –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–∞—Ä—Å–µ—Ä–∞: {e}")
    
    def _run_scheduler(self):
        """–ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
        while self.is_running:
            try:
                schedule.run_pending()
                time.sleep(60)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–µ: {e}")
                time.sleep(300)  # –ñ–¥–µ–º 5 –º–∏–Ω—É—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    def _scheduled_news_parsing(self):
        """–ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        try:
            logger.info("üïê –ù–∞—á–∞—Ç –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π...")
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π event loop –¥–ª—è –ø–æ—Ç–æ–∫–∞
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞—Ä—Å–∏–Ω–≥
                loop.run_until_complete(self._parse_and_save_news())
            finally:
                loop.close()
            
            logger.info("‚úÖ –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
    
    async def _parse_and_save_news(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ç–∏–ø—ã –Ω–æ–≤–æ—Å—Ç–µ–π
            all_news = await self.news_client.get_all_business_news(
                limit_per_category=10
            )
            
            saved_count = 0
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—É—é –Ω–æ–≤–æ—Å—Ç—å –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î
            for category, articles in all_news.items():
                for article in articles:
                    try:
                        await self.embedding_manager.save_news_article(
                            title=article['title'],
                            content=article.get('description', ''),
                            category=category,
                            source=article['source'],
                            url=article['url']
                        )
                        saved_count += 1
                        
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–∏: {e}")
                        continue
            
            logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
    
    def _analyze_sphere_impact(self, news: List[Dict], sphere: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Å—Ñ–µ—Ä—É"""
        if not news:
            return {"impact_level": "low", "relevant_news": []}
        
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        positive_keywords = ["—Ä–æ—Å—Ç", "—É–≤–µ–ª–∏—á–µ–Ω–∏–µ", "—Ä–∞–∑–≤–∏—Ç–∏–µ", "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏", "–ø—Ä–∏–±—ã–ª—å"]
        negative_keywords = ["–ø–∞–¥–µ–Ω–∏–µ", "—Å–Ω–∏–∂–µ–Ω–∏–µ", "–∫—Ä–∏–∑–∏—Å", "—É–±—ã—Ç–∫–∏", "–ø—Ä–æ–±–ª–µ–º—ã"]
        
        relevant_news = []
        impact_score = 0
        
        for article in news[:5]:  # –ë–µ—Ä–µ–º —Ç–æ–ø-5 –Ω–æ–≤–æ—Å—Ç–µ–π
            text = (article.get('title', '') + ' ' + 
                   article.get('description', '')).lower()
            
            positive_count = sum(1 for word in positive_keywords if word in text)
            negative_count = sum(1 for word in negative_keywords if word in text)
            
            article_impact = positive_count - negative_count
            impact_score += article_impact
            
            relevant_news.append({
                "title": article.get('title', ''),
                "impact": "positive" if article_impact > 0 else 
                         "negative" if article_impact < 0 else "neutral",
                "url": article.get('url', '')
            })
        
        impact_level = ("high" if abs(impact_score) >= 3 else 
                       "medium" if abs(impact_score) >= 1 else "low")
        
        return {
            "impact_level": impact_level,
            "impact_score": impact_score,
            "relevant_news": relevant_news
        }
    
    def _analyze_general_impact(self, all_news: Dict[str, List]) -> Dict[str, str]:
        """–ê–Ω–∞–ª–∏–∑ –æ–±—â–µ–≥–æ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–≥–æ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è"""
        analysis = {}
        
        for category, articles in all_news.items():
            if articles:
                # –ë–µ—Ä–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø–µ—Ä–≤—ã—Ö 3 –Ω–æ–≤–æ—Å—Ç–µ–π
                headlines = [article.get('title', '') for article in articles[:3]]
                summary = "; ".join(headlines)[:200] + "..."
                analysis[category] = summary
            else:
                analysis[category] = "–ù–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
        
        return analysis
    
    def _calculate_market_sentiment(self, all_articles: List[Dict]) -> str:
        """–†–∞—Å—á–µ—Ç —Ä—ã–Ω–æ—á–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π"""
        if not all_articles:
            return "neutral"
        
        positive_words = ["—Ä–æ—Å—Ç", "–ø—Ä–∏–±—ã–ª—å", "—É—Å–ø–µ—Ö", "—Ä–∞–∑–≤–∏—Ç–∏–µ", "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏"]
        negative_words = ["–ø–∞–¥–µ–Ω–∏–µ", "–∫—Ä–∏–∑–∏—Å", "—É–±—ã—Ç–∫–∏", "–ø—Ä–æ–±–ª–µ–º—ã", "—Å–Ω–∏–∂–µ–Ω–∏–µ"]
        
        total_sentiment = 0
        
        for article in all_articles:
            text = (article.get('title', '') + ' ' + 
                   article.get('description', '')).lower()
            
            positive_score = sum(1 for word in positive_words if word in text)
            negative_score = sum(1 for word in negative_words if word in text)
            
            total_sentiment += positive_score - negative_score
        
        if total_sentiment > 2:
            return "positive"
        elif total_sentiment < -2:
            return "negative"
        else:
            return "neutral"
    
    def _extract_key_trends(self, news: List[Dict]) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤"""
        if not news:
            return []
        
        # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö
        trends = []
        
        for article in news[:3]:
            title = article.get('title', '')
            if len(title) > 20:  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
                trends.append(title)
        
        return trends
    
    def _identify_risks_opportunities(self, news: List[Dict], sphere: str) -> Dict[str, List[str]]:
        """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∏—Å–∫–æ–≤ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π"""
        risks = []
        opportunities = []
        
        for article in news[:5]:
            text = (article.get('title', '') + ' ' + 
                   article.get('description', '')).lower()
            title = article.get('title', '')
            
            # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∏—Å–∫–æ–≤ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
            risk_indicators = ["–∫—Ä–∏–∑–∏—Å", "–ø–∞–¥–µ–Ω–∏–µ", "–ø—Ä–æ–±–ª–µ–º—ã", "—Å–∞–Ω–∫—Ü–∏–∏", "–¥–µ—Ñ–∏—Ü–∏—Ç"]
            opportunity_indicators = ["—Ä–æ—Å—Ç", "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏", "—Ä–∞–∑–≤–∏—Ç–∏–µ", "–Ω–æ–≤—ã–π", "—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ"]
            
            if any(indicator in text for indicator in risk_indicators):
                risks.append(title)
            elif any(indicator in text for indicator in opportunity_indicators):
                opportunities.append(title)
        
        return {
            "risks": risks[:3],  # –¢–æ–ø-3 —Ä–∏—Å–∫–∞
            "opportunities": opportunities[:3]  # –¢–æ–ø-3 –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
        }
    
    def _create_news_summary(self, sphere_news: List[Dict], 
                           all_news: Dict[str, List]) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–π —Å–≤–æ–¥–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        summary_parts = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Å—Ñ–µ—Ä–µ
        if sphere_news:
            summary_parts.append("–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Å—Ñ–µ—Ä–µ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:")
            for article in sphere_news[:2]:
                summary_parts.append(f"‚Ä¢ {article.get('title', '')}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–∏–µ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏
        if all_news:
            summary_parts.append("\n–û–±—â–∏–µ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏:")
            for category, articles in all_news.items():
                if articles:
                    category_name = {
                        'politics': '–ü–æ–ª–∏—Ç–∏–∫–∞',
                        'business': '–≠–∫–æ–Ω–æ–º–∏–∫–∞',
                        'stock_market': '–§–æ–Ω–¥–æ–≤—ã–π —Ä—ã–Ω–æ–∫'
                    }.get(category, category)
                    
                    top_article = articles[0]
                    summary_parts.append(f"‚Ä¢ {category_name}: {top_article.get('title', '')}")
        
        return '\n'.join(summary_parts) if summary_parts else "–ê–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
    
    def _extract_daily_trends(self, all_news: Dict[str, List]) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –µ–∂–µ–¥–Ω–µ–≤–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤"""
        trends = []
        
        for category, articles in all_news.items():
            if articles:
                top_article = articles[0]
                title = top_article.get('title', '')
                if title:
                    trends.append(f"‚Ä¢ {title}")
        
        return trends
    
    def _get_empty_analysis(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        return {
            'sphere_specific': {"impact_level": "low", "relevant_news": []},
            'general_economic': {},
            'market_sentiment': "neutral",
            'key_trends': [],
            'risks_and_opportunities': {"risks": [], "opportunities": []},
            'summary': "–ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
        }



"""
–ê–≥–µ–Ω—Ç-–≤–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–º–ø—Ç–∞–º
"""

import re
import json
import traceback
from typing import Dict, Any, List, Tuple, Optional
from utils.logger import setup_logger

logger = setup_logger()

# --- BEGIN SAFE LOGGING HELPERS ---
def _safe_json(obj) -> str:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç –ª—é–±–æ–π –æ–±—ä–µ–∫—Ç –¥–ª—è –ª–æ–≥–∞, –Ω–µ —Ä–æ–Ω—è—è –ª–æ–≥–≥–µ—Ä."""
    try:
        if isinstance(obj, str):
            # –ø–æ–ø—ã—Ç–∫–∞ –≤—ã—Ç–∞—â–∏—Ç—å JSON –∏–∑ ¬´–≥—Ä—è–∑–Ω–æ–π¬ª —Å—Ç—Ä–æ–∫–∏ –∏ –∫—Ä–∞—Å–∏–≤–æ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å
            obj_str = obj.strip()
            if obj_str.startswith("{") and obj_str.endswith("}"):
                return json.dumps(json.loads(obj_str), ensure_ascii=False, indent=2)
            return obj
        return json.dumps(obj, ensure_ascii=False, indent=2)
    except Exception:
        try:
            return str(obj)
        except Exception:
            return "<unprintable>"

def log_kv(level: str, msg: str, payload=None):
    """–õ–æ–≥ —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–æ–π. –ù–∏–∫–∞–∫–∏—Ö f-—Å—Ç—Ä–æ–∫/format/%."""
    safe_payload = _safe_json(payload)
    if level == "error":
        logger.error(msg + " | data=" + safe_payload)
    elif level == "warning":
        logger.warning(msg + " | data=" + safe_payload)
    elif level == "info":
        logger.info(msg + " | data=" + safe_payload)
    else:
        logger.debug(msg + " | data=" + safe_payload)
# --- END SAFE LOGGING HELPERS ---


class PromptValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø—Ä–æ–º–ø—Ç–∞–º"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞"""
        self.validation_rules = {
            'no_html_tags': self._check_no_html_tags,
            'no_markdown': self._check_no_markdown,
            'has_emojis': self._check_has_emojis,
            'proper_structure': self._check_proper_structure,
            'no_hash_symbols': self._check_no_hash_symbols,
            'required_emoji_sections': self._check_required_emoji_sections,
            'graphic_icons_not_bullets': self._check_graphic_icons_not_bullets,
            'astro_symbols_usage': self._check_astro_symbols_usage,
            'russian_language': self._check_russian_language,
            'no_source_mentions': self._check_no_source_mentions,
            'professional_tone': self._check_professional_tone,
            'no_direct_financial_advice': self._check_no_direct_financial_advice
        }
    
    def validate_text(self, text: str, analysis_type: str = "zodiac") -> Tuple[bool, List[str]]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–º–ø—Ç–∞–º
        
        Args:
            text (str): –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            analysis_type (str): –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            Tuple[bool, List[str]]: (–≤–∞–ª–∏–¥–µ–Ω –ª–∏ —Ç–µ–∫—Å—Ç, —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫)
        """
        errors = []
        
        for rule_name, rule_func in self.validation_rules.items():
            try:
                is_valid, error_msg = rule_func(text)
                if not is_valid:
                    errors.append(f"{rule_name}: {error_msg}")
            except Exception as e:
                errors.append(f"{rule_name}: –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ - {e}")
        
        is_valid = len(errors) == 0
        
        if not is_valid:
            logger.warning("‚ö†Ô∏è –¢–µ–∫—Å—Ç –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–æ–º–ø—Ç—É (%s): %s", analysis_type, errors)
        else:
            logger.info("‚úÖ –¢–µ–∫—Å—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–æ–º–ø—Ç—É (%s)", analysis_type)
        
        return is_valid, errors
    
    def _check_no_html_tags(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è HTML-—Ç–µ–≥–æ–≤ (–∫—Ä–æ–º–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –¥–ª—è Telegram)"""
        # –†–∞–∑—Ä–µ—à–∞–µ–º <b> –∏ <i> –¥–ª—è Telegram
        forbidden_tags = re.findall(r'<(?!/?[bi]>)[^>]+>', text)
        if forbidden_tags:
            return False, f"–ù–∞–π–¥–µ–Ω—ã –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ HTML-—Ç–µ–≥–∏: {forbidden_tags[:5]}"
        return True, ""
    
    def _check_no_markdown(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è Markdown"""
        markdown_patterns = [
            r'\*\*[^*]+\*\*',  # **–∂–∏—Ä–Ω—ã–π**
            r'__[^_]+__',      # __–∂–∏—Ä–Ω—ã–π__
            r'\*[^*]+\*',      # *–∫—É—Ä—Å–∏–≤*
            r'_[^_]+_',        # _–∫—É—Ä—Å–∏–≤_
            r'^#{1,6}\s',      # # –∑–∞–≥–æ–ª–æ–≤–∫–∏
        ]
        
        for pattern in markdown_patterns:
            if re.search(pattern, text, re.MULTILINE):
                return False, f"–ù–∞–π–¥–µ–Ω Markdown: {pattern}"
        
        return True, ""
    
    def _check_has_emojis(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —ç–º–æ–¥–∑–∏"""
        emoji_pattern = r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002600-\U000027BF\U0001F900-\U0001F9FF]'
        emojis = re.findall(emoji_pattern, text)
        
        if len(emojis) < 5:
            return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —ç–º–æ–¥–∑–∏: {len(emojis)} (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 5)"
        
        return True, ""
    
    def _check_proper_structure(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ —Å —ç–º–æ–¥–∑–∏
        required_sections = ['üåü', 'üíé', 'üöÄ', '‚ö†Ô∏è']
        found_sections = []
        
        for section in required_sections:
            if section in text:
                found_sections.append(section)
        
        if len(found_sections) < 3:
            return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {found_sections} (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 3 –∏–∑ {required_sections})"
        
        return True, ""
    
    def _check_no_hash_symbols(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Å–∏–º–≤–æ–ª–æ–≤ #"""
        if '#' in text:
            hash_lines = [line.strip() for line in text.split('\n') if '#' in line]
            return False, f"–ù–∞–π–¥–µ–Ω—ã —Å–∏–º–≤–æ–ª—ã #: {hash_lines[:3]}"
        
        return True, ""
    
    def _check_required_emoji_sections(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö 6 –±–ª–æ–∫–æ–≤ –∏–∑ prompts.py"""
        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –±–ª–æ–∫–∏ –∏–∑ COMPANY_ZODIAC_PROMPT
        required_blocks = [
            ('üåü', '–í–õ–ò–Ø–ù–ò–ï –ó–ù–ê–ö–ê –ó–û–î–ò–ê–ö–ê –ù–ê –°–£–î–¨–ë–£', 300),
            ('üîÆ', '–í–õ–ò–Ø–ù–ò–ï –ü–õ–ê–ù–ï–¢ –ò –ú–ï–°–¢–ê –†–ï–ì–ò–°–¢–†–ê–¶–ò–ò', 250),
            ('üíé', '–°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´ –ò –ü–û–¢–ï–ù–¶–ò–ê–õ –†–û–°–¢–ê', 300),
            ('üßò', '–§–ò–õ–û–°–û–§–°–ö–ê–Ø –ö–û–ù–¶–ï–ü–¶–ò–Ø –ö–û–ú–ü–ê–ù–ò–ò', 250),
            ('‚ö†Ô∏è', '–ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ï –†–ò–°–ö–ò –ò –í–´–ó–û–í–´', 200),
            ('üíº', '–ë–ò–ó–ù–ï–°-–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ò –°–¢–†–ê–¢–ï–ì–ò–ò', 200)
        ]
        
        missing_blocks = []
        
        for emoji, block_name, min_words in required_blocks:
            if emoji not in text:
                missing_blocks.append(f"{emoji} {block_name}")
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π –æ–±—ä–µ–º –±–ª–æ–∫–∞
                lines_with_emoji = [line for line in text.split('\n') if emoji in line]
                if len(lines_with_emoji) == 0:
                    missing_blocks.append(f"{emoji} {block_name} (–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)")
        
        if missing_blocks:
            return False, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –±–ª–æ–∫–∏ –∏–∑ prompts.py: {missing_blocks[:3]}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–∏–π –æ–±—ä–µ–º (–º–∏–Ω–∏–º—É–º 1500 —Å–ª–æ–≤)
        word_count = len(text.split())
        if word_count < 1000:  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –æ–±—ä–µ–º —Ç–µ–∫—Å—Ç–∞: ~{word_count} —Å–ª–æ–≤ (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 1500)"
        
        return True, ""
    
    def _check_russian_language(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞"""
        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
        cyrillic_chars = len(re.findall(r'[–∞-—è—ë]', text.lower()))
        total_letters = len(re.findall(r'[a-zA-Z–∞-—è—ë–ê-–Ø–Å]', text))
        
        if total_letters > 0:
            cyrillic_ratio = cyrillic_chars / total_letters
            if cyrillic_ratio < 0.8:
                return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {cyrillic_ratio:.2%} –∫–∏—Ä–∏–ª–ª–∏—Ü—ã"
        
        return True, ""
    
    def _check_no_source_mentions(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        source_keywords = [
            '–∏—Å—Ç–æ—á–Ω–∏–∫', '–¥–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã', '—Å–æ–≥–ª–∞—Å–Ω–æ', '–ø–æ –¥–∞–Ω–Ω—ã–º',
            'newsdata', 'prokerala', 'gemini', 'openai', 'api'
        ]
        
        text_lower = text.lower()
        found_sources = [word for word in source_keywords if word in text_lower]
        
        if found_sources:
            return False, f"–ù–∞–π–¥–µ–Ω—ã —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {found_sources}"
        
        return True, ""
    
    def _check_graphic_icons_not_bullets(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∏–∫–æ–Ω–æ–∫ –≤–º–µ—Å—Ç–æ –æ–±—ã—á–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤"""
        # –ò—â–µ–º –æ–±—ã—á–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
        bullet_patterns = [r'^\s*\*\s', r'^\s*-\s', r'^\s*‚Ä¢\s']
        found_bullets = []
        
        for pattern in bullet_patterns:
            matches = re.findall(pattern, text, re.MULTILINE)
            if matches:
                found_bullets.extend(matches)
        
        if found_bullets:
            return False, f"–ù–∞–π–¥–µ–Ω—ã –æ–±—ã—á–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã –≤–º–µ—Å—Ç–æ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∏–∫–æ–Ω–æ–∫: {found_bullets[:3]}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∏–∫–æ–Ω–æ–∫ –∏–∑ prompts.py
        required_icons = ['‚≠ê', 'üéØ', 'üí´', '‚ö°', 'üî•', 'üíé', 'üöÄ', '‚ö†Ô∏è', 'üí∞']
        found_icons = [icon for icon in required_icons if icon in text]
        
        if len(found_icons) < 3:
            return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∏–∫–æ–Ω–æ–∫. –ù–∞–π–¥–µ–Ω–æ: {found_icons}, –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 3 –∏–∑ {required_icons}"
        
        return True, ""
    
    def _check_astro_symbols_usage(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        astro_symbols = ['‚ôà', '‚ôâ', '‚ôä', '‚ôã', '‚ôå', '‚ôç', '‚ôé', '‚ôè', '‚ôê', '‚ôë', '‚ôí', '‚ôì', '‚òâ', '‚òΩ', '‚òø', '‚ôÄ', '‚ôÇ', '‚ôÉ', '‚ôÑ', '‚õ¢', '‚ôÜ', '‚ôá']
        found_symbols = [symbol for symbol in astro_symbols if symbol in text]
        
        if len(found_symbols) < 2:
            return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤. –ù–∞–π–¥–µ–Ω–æ: {found_symbols}, –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2"
        
        return True, ""
    
    def _check_professional_tone(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–æ–Ω–∞"""
        # –ò—â–µ–º –Ω–µ–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã
        unprofessional_phrases = [
            '–∏–∑–≤–∏–Ω–∏—Ç–µ', '–ø—Ä–æ—Å—Ç–∏—Ç–µ', '–∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é', '–≤–æ–∑–º–æ–∂–Ω–æ', '–Ω–∞–≤–µ—Ä–Ω–æ–µ', '–º–æ–∂–µ—Ç –±—ã—Ç—å',
            '—è –¥—É–º–∞—é', '—è —Å—á–∏—Ç–∞—é', '–ø–æ –º–æ–µ–º—É –º–Ω–µ–Ω–∏—é'
        ]
        
        text_lower = text.lower()
        found_unprofessional = [phrase for phrase in unprofessional_phrases if phrase in text_lower]
        
        if found_unprofessional:
            return False, f"–ù–∞–π–¥–µ–Ω—ã –Ω–µ–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã: {found_unprofessional[:3]}"
        
        return True, ""
    
    def _check_no_direct_financial_advice(self, text: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –ø—Ä—è–º—ã—Ö —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Å–æ–≤–µ—Ç–æ–≤"""
        direct_advice_patterns = [
            r'–ø–æ–∫—É–ø–∞–π—Ç–µ\s+–∞–∫—Ü–∏–∏', r'–ø—Ä–æ–¥–∞–≤–∞–π—Ç–µ\s+–∞–∫—Ü–∏–∏', r'–∏–Ω–≤–µ—Å—Ç–∏—Ä—É–π—Ç–µ\s+–≤',
            r'–∫—É–ø–∏—Ç–µ\s+', r'–ø—Ä–æ–¥–∞–π—Ç–µ\s+', r'–≤–ª–æ–∂–∏—Ç–µ\s+–¥–µ–Ω—å–≥–∏'
        ]
        
        text_lower = text.lower()
        found_advice = []
        
        for pattern in direct_advice_patterns:
            if re.search(pattern, text_lower):
                found_advice.append(pattern)
        
        if found_advice:
            return False, f"–ù–∞–π–¥–µ–Ω—ã –ø—Ä—è–º—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Å–æ–≤–µ—Ç—ã: {found_advice[:2]}"
        
        return True, ""
    
    def fix_text(self, text: str) -> str:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text (str): –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            str: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        # –£–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ HTML-—Ç–µ–≥–∏ (—Å–æ—Ö—Ä–∞–Ω—è–µ–º <b> –∏ <i> –¥–ª—è Telegram)
        text = re.sub(r'<(?!/?[bi]>)[^>]+>', '', text)
        
        # –£–±–∏—Ä–∞–µ–º Markdown
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)  # **–∂–∏—Ä–Ω—ã–π**
        text = re.sub(r'__([^_]+)__', r'\1', text)      # __–∂–∏—Ä–Ω—ã–π__
        text = re.sub(r'\*([^*]+)\*', r'\1', text)      # *–∫—É—Ä—Å–∏–≤*
        text = re.sub(r'_([^_]+)_', r'\1', text)        # _–∫—É—Ä—Å–∏–≤_
        
        # –£–±–∏—Ä–∞–µ–º —Å–∏–º–≤–æ–ª—ã # –∏ –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ —ç–º–æ–¥–∑–∏
        text = re.sub(r'^#{1,6}\s*(.+)$', r'üåü \1', text, flags=re.MULTILINE)
        text = re.sub(r'###\s*(.+)', r'üíé \1', text)
        text = re.sub(r'##\s*(.+)', r'üöÄ \1', text)
        text = re.sub(r'#\s*(.+)', r'‚≠ê \1', text)
        
        # –ó–∞–º–µ–Ω—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
        text = re.sub(r'^---+$', '', text, flags=re.MULTILINE)
        text = re.sub(r'^===+$', '', text, flags=re.MULTILINE)
        
        # –£–±–∏—Ä–∞–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        text = re.sub(r'(–∏—Å—Ç–æ—á–Ω–∏–∫|–¥–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã|—Å–æ–≥–ª–∞—Å–Ω–æ|–ø–æ –¥–∞–Ω–Ω—ã–º)', '', text, flags=re.IGNORECASE)
        text = re.sub(r'(newsdata|prokerala|gemini|openai|api)', '', text, flags=re.IGNORECASE)
        
        # –ó–∞–º–µ–Ω—è–µ–º –æ–±—ã—á–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã –Ω–∞ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∏–∫–æ–Ω–∫–∏ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏—Ö –µ—â–µ –Ω–µ—Ç)
        text = re.sub(r'^\s*\*\s+(?!‚≠ê|üí´|üéØ|‚ö°|üî•|üíé|üöÄ|‚ö†Ô∏è|üí∞)(.+)', r'‚≠ê \1', text, flags=re.MULTILINE)
        text = re.sub(r'^\s*-\s+(?!‚≠ê|üí´|üéØ|‚ö°|üî•|üíé|üöÄ|‚ö†Ô∏è|üí∞)(.+)', r'üí´ \1', text, flags=re.MULTILINE)
        text = re.sub(r'^\s*‚Ä¢\s+(?!‚≠ê|üí´|üéØ|‚ö°|üî•|üíé|üöÄ|‚ö†Ô∏è|üí∞)(.+)', r'üéØ \1', text, flags=re.MULTILINE)
        
        # –£–±–∏—Ä–∞–µ–º –Ω–µ–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã
        unprofessional_replacements = {
            '–∏–∑–≤–∏–Ω–∏—Ç–µ': '', '–ø—Ä–æ—Å—Ç–∏—Ç–µ': '', '–∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é': '',
            '–≤–æ–∑–º–æ–∂–Ω–æ': '–≤–µ—Ä–æ—è—Ç–Ω–æ', '–Ω–∞–≤–µ—Ä–Ω–æ–µ': '—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ', '–º–æ–∂–µ—Ç –±—ã—Ç—å': '–≤–µ—Ä–æ—è—Ç–Ω–æ',
            '—è –¥—É–º–∞—é': '', '—è —Å—á–∏—Ç–∞—é': '', '–ø–æ –º–æ–µ–º—É –º–Ω–µ–Ω–∏—é': ''
        }
        
        for phrase, replacement in unprofessional_replacements.items():
            text = re.sub(phrase, replacement, text, flags=re.IGNORECASE)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ 6 –±–ª–æ–∫–æ–≤ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        if 'üåü' not in text or '–í–õ–ò–Ø–ù–ò–ï –ó–ù–ê–ö–ê –ó–û–î–ò–ê–ö–ê' not in text:
            text = 'üåü –í–õ–ò–Ø–ù–ò–ï –ó–ù–ê–ö–ê –ó–û–î–ò–ê–ö–ê –ù–ê –°–£–î–¨–ë–£ –ö–û–ú–ü–ê–ù–ò–ò\n\n' + text
        if 'üîÆ' not in text or '–í–õ–ò–Ø–ù–ò–ï –ü–õ–ê–ù–ï–¢' not in text:
            text = text + '\n\nüîÆ –í–õ–ò–Ø–ù–ò–ï –ü–õ–ê–ù–ï–¢ –ò –ú–ï–°–¢–ê –†–ï–ì–ò–°–¢–†–ê–¶–ò–ò'
        if 'üíé' not in text or '–°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´' not in text:
            text = text + '\n\nüíé –°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´ –ò –ü–û–¢–ï–ù–¶–ò–ê–õ –†–û–°–¢–ê'
        if 'üßò' not in text or '–§–ò–õ–û–°–û–§–°–ö–ê–Ø –ö–û–ù–¶–ï–ü–¶–ò–Ø' not in text:
            text = text + '\n\nüßò –§–ò–õ–û–°–û–§–°–ö–ê–Ø –ö–û–ù–¶–ï–ü–¶–ò–Ø –ö–û–ú–ü–ê–ù–ò–ò'
        if '‚ö†Ô∏è' not in text or '–ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ï –†–ò–°–ö–ò' not in text:
            text = text + '\n\n‚ö†Ô∏è –ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ï –†–ò–°–ö–ò –ò –í–´–ó–û–í–´'
        if 'üíº' not in text or '–ë–ò–ó–ù–ï–°-–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò' not in text:
            text = text + '\n\nüíº –ë–ò–ó–ù–ï–°-–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ò –°–¢–†–ê–¢–ï–ì–ò–ò'
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –º–µ–∂–¥—É —Ä–∞–∑–¥–µ–ª–∞–º–∏ —Å —ç–º–æ–¥–∑–∏
        text = re.sub(r'(\n)(üåü|üíé|üöÄ|‚ö†Ô∏è|üìà|üîÆ|üíº|üéØ|üí°|‚ú®)', r'\1\n\2', text)
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø–µ—Ä–µ–Ω–æ—Å—ã
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
        
        return text.strip()


class ValidationAgent:
    """–ê–≥–µ–Ω—Ç –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ —Å RLHF"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Anthropic –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π
        try:
            from validation_agent.claude_validator import AnthropicValidationAgent
            self.claude_agent = AnthropicValidationAgent()
            self.use_claude = True
            logger.info("‚úÖ Anthropic –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            logger.warning("‚ö†Ô∏è Anthropic –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: %s", str(e))
            # –†–µ–∑–µ—Ä–≤–Ω—ã–π –ª–æ–∫–∞–ª—å–Ω—ã–π –≤–∞–ª–∏–¥–∞—Ç–æ—Ä
            self.validator = PromptValidator()
            self.use_claude = False
            logger.info("‚úÖ –†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    async def validate_and_fix(self, text: str, analysis_type: str = "zodiac", original_prompt: str = "") -> str:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –º–∏–Ω–∏–º—É–º 7 –±–∞–ª–ª–æ–≤
        
        Args:
            text (str): –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            analysis_type (str): –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞
            original_prompt (str): –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            
        Returns:
            str: –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        try:
            if self.use_claude and hasattr(self, 'claude_agent'):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º Anthropic –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π
                logger.info("ü§ñ –ò—Å–ø–æ–ª—å–∑—É–µ–º Anthropic –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–ª—è %s (—Ü–µ–ª—å: 7+ –±–∞–ª–ª–æ–≤)", analysis_type)
                
                # –°–¢–†–ï–ú–ò–ú–°–Ø –ö –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ô –û–¶–ï–ù–ö–ï 10 –ë–ê–õ–õ–û–í
                logger.info("üéØ –¶–ï–õ–¨: –¥–æ—Å—Ç–∏—á—å –æ—Ü–µ–Ω–∫–∏ 10.0/10 (—Å—Ç—Ä–µ–º–∏–º—Å—è –∫ —Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤—É)")
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é —á–µ—Ä–µ–∑ Claude —Å –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–º —É–ª—É—á—à–µ–Ω–∏–µ–º
                improved_text = await self.claude_agent.validate_and_fix(
                    text=text,
                    analysis_type=analysis_type,
                    original_prompt=original_prompt
                )
                
                # –ü–æ–ª—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É
                final_result = await self.claude_agent.claude_validator.validate_and_score(
                    improved_text, original_prompt, analysis_type
                )
                final_score = final_result.get('score', 7.0)
                logger.info("üèÜ Anthropic –≤–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: %.1f/10", final_score)
                return improved_text
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞–ª–∏–¥–∞—Ç–æ—Ä
                logger.info("üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–ª—è %s", analysis_type)
                return await self._fallback_validation(text, analysis_type, original_prompt)
                
        except Exception as e:
            logger.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: %s", str(e))
            logger.error("Stacktrace: %s", traceback.format_exc())
            # –í–°–ï–ì–î–ê –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ö–æ—Ç—è –±—ã –±–∞–∑–æ–≤—É—é –æ—á–∏—Å—Ç–∫—É
            return self._basic_cleanup(text)
    
    def _basic_cleanup(self, text: str) -> str:
        """–ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        if not text:
            return "–ê–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        text = re.sub(r'<(?!/?[bi]>)[^>]+>', '', text)  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ HTML
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã
        
        return text.strip()
    
    async def _fallback_validation(self, text: str, analysis_type: str, original_prompt: str) -> str:
        """–†–µ–∑–µ—Ä–≤–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Claude"""
        import asyncio
        
        if not hasattr(self, 'validator'):
            self.validator = PromptValidator()
        
        current_text = text
        max_iterations = 2  # –£–º–µ–Ω—å—à–∞–µ–º –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
        iteration = 0
        
        logger.info("üîç –†–µ–∑–µ—Ä–≤–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Ç–∏–ø–∞ '%s'", analysis_type)
        
        while iteration < max_iterations:
            iteration += 1
            logger.info("üîÑ –ò—Ç–µ—Ä–∞—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ #%d", iteration)
            
            # –õ–æ–∫–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
            is_valid_local, local_errors = self.validator.validate_text(current_text, analysis_type)
            
            if is_valid_local:
                logger.info("‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ %d –∏—Ç–µ—Ä–∞—Ü–∏–π", iteration)
                return current_text
            
            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
            current_text = self.validator.fix_text(current_text)
            logger.info("üîß –¢–µ–∫—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ (–∏—Ç–µ—Ä–∞—Ü–∏—è %d)", iteration)
            
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏
            if iteration < max_iterations:
                await asyncio.sleep(0.1)
        
        return current_text
    
    async def validate_and_fix_with_rlhf(self, 
                                       text: str, 
                                       analysis_type: str = "zodiac", 
                                       original_prompt: str = "",
                                       generation_function=None,
                                       generation_params: Optional[Dict[str, Any]] = None) -> Tuple[str, Dict[str, Any]]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞
        
        Args:
            text (str): –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            analysis_type (str): –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞
            original_prompt (str): –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            generation_function: –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            generation_params (Dict): –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            Tuple[str, Dict]: (—É–ª—É—á—à–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞)
        """
        logger.info("üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è %s", analysis_type)
        improved_text = await self.validate_and_fix(text, analysis_type, original_prompt)
        return improved_text, {'final_score': 7.0, 'method': 'anthropic'}
